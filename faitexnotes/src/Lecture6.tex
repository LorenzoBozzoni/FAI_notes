\section{Uninformed search strategies}
\textbf{Search Strategies}: a search strategy determines the ordering of nodes in the frontier. Selecting a node amounts to decide the ordering of the frontier and to select the first node. \\
\textbf{Uninformed Search Strategies}: they use only the information contained in the problem formulation.\\

The Five Elements of Uninformed Search Strategies
\begin{enumerate}
    \item The set of states (and an initial state)
    \item Function actions()
    \item Function result()
    \item Goal test
    \item Step cost
\end{enumerate}

\subsection{Tree-search algorithm}
\begin{Verbatim}[numbers=left, frame=single]
Initialize the root of the tree with the initial state of problem
LOOP DO
    IF there are no more nodes candidate for expansion
        THEN RETURN failure
    select a node not yet expanded
    IF the node corresponds to a goal state
        THEN RETURN the corresponding solution
        ELSE expand the chosen node, adding the resulting nodes to the tree
\end{Verbatim}

\subsection{Graph-search algorithm}
Here is introduced the closed list in order to avoid visiting the same node multiple times.
\begin{Verbatim}[numbers=left, frame=single]
initialize the root of the tree with the initial state of problem
initialize the closed list to the empty set
LOOP DO
    IF there are no more nodes candidate for expansion
        THEN RETURN failure
    choose a node not yet expanded
    IF the node corresponds to a goal state
        THEN RETURN the corresponding solution
        ELSE IF the state corresponding to the node is not in the closed list
        THEN add the corresponding state to the closed list expand the chosen node, adding the
        resulting nodes to the tree
\end{Verbatim}

\subsection{Evaluation of search strategies}
\begin{itemize}
    \item \textbf{Completeness}: is the search strategy guaranteed to find a solution when there is one?
    \item \textbf{(Cost) Optimality}: does the search strategy find the optimal solution (minimum cost solution)?
    \item \textbf{(Time and Space) Complexity}: how much time and memory does the search strategy take to perform the search?
    \item \textbf{Parameters}: 
    \begin{itemize}
        \item \textbf{b}, the branching factor of the search tree (the maximum number of successors of any node)
        \item \textbf{d}, the depth d of the shallowest goal node
    \end{itemize}
\end{itemize}

When the branching factor is large, the problem is difficult, the number of nodes will grow quickly. When the value of d is large the closest solution will require more exploration of the search tree. Sometimes, the depth d is fixed for any solution (like for example, in the eight-queen puzzle)

\subsection{Breadth-first search}
First, it selects the root, then all the root’s successors, then all their successors, and so on. In breadth-first search, all nodes at level k of the search tree must be selected before selecting any node at level $k+1$.

Breadth-first search always selects the node with
minimum depth (the shallowest one). When more nodes are at the same depth, a tie-breaker is applied determined by the insertion order.\\

Example:
\begin{center}
    \includegraphics[scale=0.4]{../images/6/BreadthFirstExample.png}
\end{center}
The node "2" is expanded before the node "3" so in a certain istant the frontier is: 3,4,5 as it is written also in the figure below. The node "7" is not immediately recognized as a goal, it is inserted in the frontier before. Once the goal node is reached, the path to the root is selected as solution.

Breadth-first search can be implemented by considering the frontier a FIFO (First In First Out) queue. The new nodes are appended at the end of the frontier. Thus, the nodes generated first are selected first.
\begin{center}
    \includegraphics[scale=0.4]{../images/6/BreadthFirstFrontier.png}
\end{center}

\subsubsection{Evaluation of Breadth-First Search}
\begin{itemize}
    \item Breadth-first search is complete: assuming b is finite
    \item Breadth-first search is optimal: it finds the shallowest solution when step costs are all equal (e.g., they are unitary). When the path cost to any node is a non-decreasing function of the depth of the node. The cost for the second level is greater than the first, and so on.
    \item Complexity: breadth-first search has temporal and spatial (worst-case) complexity of $O(bd+1)$ nodes. The root of the search tree generates b nodes at level 1. Each one of them generates b nodes, totaling $b^2$ nodes at level 2. Thus, at level d+1 there will be $b^{d+1} - b$ nodes
\end{itemize}

Worst case of Breadth-First Search:
\begin{center}
    \includegraphics[scale=0.4]{../images/6/WorstCaseBreadthFirst.png}
\end{center}
In breadth-first search, we can perform the goal test when a node is generated, instead of when it is selected from the frontier. This variant is still complete and optimal (when the path cost to any node is a non-decreasing function of the depth of the node). This variant has temporal and spatial (worst-case) complexity of $O(b^d)$ nodes since we avoid
expanding a node before adding it to the frontier.
\begin{center}
    \includegraphics[scale=0.4]{../images/6/WorstCaseVariant.png}
\end{center}
Here is the breadth-first search algorithm from the textbook:
\begin{center}
    \includegraphics[scale=0.4]{../images/6/BreadthFirstAlgorithm.png}
\end{center}
And the python version with the goal test when a node is selected from the frontier is:
\begin{Verbatim}[numbers=left, frame=single]
def breadth_first_search(problem, verbose=False):
    node = Node(problem.initial)
    frontier = FIFOQueue([node])
    reached = {problem.initial}
    while frontier:
        node = frontier.pop()
        if problem.is_goal(node.state):
            return node
        for child in expand(problem, node):
            s = child.state
            if s not in reached:
                reached.add(s)
                frontier.appendleft(child)
    return failure,visited_states
\end{Verbatim}
A similar python version with the goal test when a node is generated:
\begin{Verbatim}[numbers=left, frame=single]
def breadth_first_search_early_goal_test(problem):
    node = Node(problem.initial)
    if problem.is_goal(problem.initial):
        return node
    frontier = FIFOQueue([node])
    reached = {problem.initial}
    while frontier:
        node = frontier.pop()
        for child in expand(problem, node):
            s = child.state
            if problem.is_goal(s):
               return child
            if s not in reached:
                reached.add(s)
                frontier.appendleft(child)
    return failure
\end{Verbatim}
We could implement breadth-first search as a call to Best-First-Search where the evaluation function f(n) is the depth of the node (the number of actions it takes to reach the node). However, the native implementation is more efficient since:
\begin{itemize}
    \item A first-in-first-out queue will be faster than a priority queue
    \item Reached can be a set of states rather than a mapping from states to nodes, because once we’ve reached a state, we can never find a better path to the state
    \item Thus, breadth-first search can perform an early goal test, checking whether a node is a solution as soon as it is generated, rather than the late goal test that best-first search uses,
    waiting until a node is popped off the queue
\end{itemize}
 
\subsection{Uniform cost search}
It generalizes breadth-first search: it sorts the nodes in the frontier according to their increasing path cost from the root and it selects the node n with the smallest path cost from the root. It does not necessarily choose the shallowest node! It is implemented as best-first-search where
the evaluation function f(n) returns the path cost.
\begin{center}
    \includegraphics[scale=0.4]{../images/6/UniformCostSearch.png}
\end{center}

\subsubsection{Evaluation of Uniform-Cost Search}
\begin{itemize}
    \item Uniform-cost search is complete: assuming $b$ finite and step costs larger than a small positive $\epsilon$
    \item Uniform-cost search is optimal: uniform-cost search expands nodes in order of their optimal path costs
    \item Complexity: Uniform-cost search has temporal and spatial worst-case complexity of $O(b^{(1+ \lfloor C^*/\epsilon \rfloor)})$ nodes, where $C^*$ is the cost of the optimal solution. The fraction at the exponent represents the depth of the tree since $\epsilon$ is very small will always be choosen by the algorithm.
\end{itemize}

\subsection{Depth-first search}
First, it selects the root node, then, it expands one of its successors,
then one of its successors, and so on. Depth-first search always selects the node at maximum depth (the deepest one). When it reaches a node without successors, it “backtracks” and chooses one of the deepest nodes not yet chosen.
\begin{center}
    \includegraphics[scale=0.4]{../images/6/DepthFirstSearch.png}
\end{center}

Depth-first search can be implemented by representing the frontier as a Last-In-First-Out (LIFO) queue. Since it is a stack, it can be implemented both explicitely by a data structure or implicitely by means of recursive calls. It is like a breadth-first search with LIFO instead of FIFO. The generated successor nodes are inserted at the front of the frontier. The most recently generated nodes are selected first.
\begin{center}
    \includegraphics[scale=0.4]{../images/6/DepthFirstExample.png}
\end{center}

The python \textit{recursive implementation} of depth-first search is:
\begin{Verbatim}[numbers=left, frame=single]
def depth_first_recursive_search(problem, node=None):
    if node is None:
        node = Node(problem.initial)
    if problem.is_goal(node.state):
        return node
    elif is_cycle(node):
        return failure
    else:
        for child in expand(problem, node):
            result = depth_first_recursive_search(problem, child)
            if result:
                return result
    return failure
\end{Verbatim}
The python \textit{iterative implementation} of depth-first search is:
\begin{Verbatim}[numbers=left, frame=single]
def depth_first_search_iterative(problem):
    "Search deepest nodes in the search tree first."
    frontier = LIFOQueue([Node(problem.initial)])
    result = failure
    while frontier:
        node = frontier.pop()
        if problem.is_goal(node.state):
            return node
        elif not is_cycle(node):
            for child in expand(problem, node):
                frontier.append(child)
    return result

def is_cycle(node, k=30):
    "Does this node form a cycle of length k or less?"
    def find_cycle(ancestor, k):
        return (ancestor is not None and k > 0 and 
        (ancestor.state == node.state or find_cycle(ancestor.parent, k - 1)))
    return find_cycle(node.parent, k)
\end{Verbatim}

\subsubsection{Evaluation of Depth-First Search}
\begin{itemize}
    \item Depth-first search is not complete: it can follow path of infinite length
    \item Depth-first search is not optimal: it does not find the shallowest solution, might go very deeply in a wrong direction.
    \item Complexity: given the maximum depth of the search tree $m$, depth-first has spatial (worse-case) complexity of $O(bm)$ nodes. It has temporal (worst-case) complexity of $O(b^m)$ nodes; $m$ could be infinite; $m\geq d$ (often $m \gg d$). At each step of the search, only a single path (from the root to a leaf node) must be stored
    in memory; also, the nodes not yet expanded at each level should be stored
\end{itemize}
Also depth-first search could be implemented as a call to best-first
search where the evaluation function f(n) is the negative of the depth.
However, it is usually implemented not as a graph search but as
a tree-like search that does not keep a table of reached states.

\subsection{Depth-limited search}
Depth-limited search is a depth-first search with a predetermined depth limit L. Nodes at level L are assumed to have no successors. Depth-limited search is complete when $L\geq d$, however, d is often unknown. \\
Depth-limited search is not optimal. Complexity: Depth-limited search has spatial (worst-case) complexity of $O(bL)$ nodes, it has temporal (worst-case) complexity of $O(b^L)$ nodes.\\

Python recursive implementation of depth-limited search:
\begin{Verbatim}[numbers=left, frame=single]    
def depth_limited_search(problem, limit=40):
    "Search deepest nodes in the search tree first."
    frontier = LIFOQueue([Node(problem.initial)])
    result = failure
    while frontier:
        node = frontier.pop()
        if problem.is_goal(node.state):
            return node
        elif len(node) >= limit:
            result = cutoff
        elif not is_cycle(node):
            for child in expand(problem, node):
                frontier.append(child)
    return result
\end{Verbatim}

\subsection{Iterative deepening search}
It performs repeated depth-limited searches,
increasing the depth limit $L: L=0, L=1, L=2, \dots$.
Recursive python implementation of iterative deepening search:
\begin{Verbatim}[numbers=left, frame=single] 
def iterative_deepening_search(problem):
    "Do depth-limited search with increasing depth limits."
    for limit in range(1, sys.maxsize):
        result = depth_limited_search(problem, limit)
        if result != cutoff:
    return result
\end{Verbatim}

\begin{center}
    \includegraphics[scale=0.4]{../images/6/IterativeDeepeningSearch.png}
\end{center}
Example of iterative deepening search:
\begin{multicols}{3}
\begin{center}
    \includegraphics[scale=0.15]{../images/6/IterativeDeepeningEx1.png}
    \includegraphics[scale=0.15]{../images/6/IDEx2.png}
    \includegraphics[scale=0.15]{../images/6/IDEx3.png}
\end{center}
\end{multicols}
Every time the depth is increased,
the entire tree is regenerated
(optimization exists)

\subsubsection{Evaluation of Iterative Deepening Search}
\begin{itemize}
    \item Iterative deepening search is complete (assuming b finite): if a solution exists, eventually $L=d$
    \item Iterative deepening search is optimal: when the step costs are all equal (as in breadth-first search)
    \item Complexity: iterative deepening search has spatial (worst-case) complexity of $O(bd)$ nodes. It has temporal (worst-case) complexity of $O(b^d)$ nodes
\end{itemize}

\subsection{Bidirectional search}
It performs two searches in parallel a “forward” search from the initial state to a goal state a “backward” search from a goal state to the initial state.
Example of bidirectional search:
\begin{center}
    \includegraphics[scale=0.4]{../images/6/BidirectionalSearch.png}
\end{center}

\subsection{Tree-search Vs. Graph-search algorithms}
Tree-search algorithms work well when the state space is a tree. Graph-search algorithms work well when the state space is a graph (general case).

Several variants are possible. For example, repeated states can be checked when a node is generated (not when a node is expanded). Trade-off between memory usage for storing the closed list and time spent to check the closed list.

\subsection{Summary of uninformed search strategies}
\begin{center}
    \includegraphics[scale=0.4]{../images/6/UninformedSummary.png}
\end{center}
